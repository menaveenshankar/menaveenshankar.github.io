[{"authors":null,"categories":null,"content":" Music: Martial arts: Sports:  The parent folder may be renamed, for example, to docs for project documentation or course for creating an online course.\n","date":1536444000,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1536444000,"objectID":"3055eb56c576709905b42c9c324319a8","permalink":"https://menaveenshankar.github.io/misc/","publishdate":"2018-09-09T00:00:00+02:00","relpermalink":"/misc/","section":"misc","summary":"Music: Martial arts: Sports:  The parent folder may be renamed, for example, to docs for project documentation or course for creating an online course.","tags":null,"title":"Overview","type":"docs"},{"authors":["Alexander Frickenstein, Manoj Rohit Vemparala, Jakob Mayr,  _Naveen Shankar Nagaraja_, Christian Unger, Federico Tombari, Walter Stechele"],"categories":null,"content":"","date":1590962400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1590962400,"objectID":"baa00c8f255b76ab1b3ca82ffee9a28e","permalink":"https://menaveenshankar.github.io/publication/icra20/","publishdate":"2020-06-01T00:00:00+02:00","relpermalink":"/publication/icra20/","section":"publication","summary":"Driveable area detection is a key component for various applications in the field of autonomous driving (AD), such as ground-plane detection, obstacle detection and maneuver planning. Additionally, bulky and over-parameterized networks can be easily forgone and replaced with smaller networks for faster inference on embedded systems. The driveable area detection, posed as a two class segmentation task, can be efficiently modeled with slim binary networks. This paper proposes a novel binarized driveable area detection network (binary DAD-Net), which uses only binary weights and activations in the encoder, the bottleneck, and the decoder part. The latent space of the bottleneck is efficiently increased (x32 - x16 downsampling) through binary dilated convolutions, learning more complex features. Along with automatically generated training data, the binary DAD-Net outperforms state-of-the-art semantic segmentation networks on public datasets. In comparison to a full-precision model, our approach has a x14.3 reduced compute complexity on an FPGA and it requires only 0.9MB memory resources. Therefore, commodity SIMD-based AD-hardware is capable of accelerating the binary DAD-Net.","tags":[],"title":"Binary DAD-Net: Binarized Driveable Area Detection Network for Autonomous Driving","type":"publication"},{"authors":["Tessa Heiden, _Naveen Shankar Nagaraja_, Christian Weiss, Efstratios Gavves"],"categories":null,"content":"","date":1569016800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569016800,"objectID":"49d887d1dadd64081ef8d3103f26ab62","permalink":"https://menaveenshankar.github.io/publication/bmvc19_ws/","publishdate":"2019-09-21T00:00:00+02:00","relpermalink":"/publication/bmvc19_ws/","section":"publication","summary":"Navigating complex urban environments safely is a key to realize fully autonomous systems. Predicting future locations of vulnerable road users, such as pedestrians and cyclists, thus, has received a lot of attention in the recent years. While previous works have addressed modeling interactions with the static (obstacles) and dynamic (humans) environment agents, we address an important gap in trajectory prediction. We propose SafeCritic, a model that synergizes generative adversarial networks for generating multiple \"real\" trajectories with reinforcement learning to generate \"safe\" trajectories. The Discriminator evaluates the generated candidates on whether they are consistent with the observed inputs. The Critic network is environmentally aware to prune trajectories that are in collision or are in violation with the environment. The auto-encoding loss stabilizes training and prevents mode-collapse. We demonstrate results on two large scale data sets with a considerable improvement over state-of-the-art. We also show that the Critic is able to classify the safety of trajectories.","tags":[],"title":"SafeCritic: Collision-Aware Trajectory Prediction","type":"publication"},{"authors":["Oliver Scheel, _Naveen Shankar Nagaraja_, Loren Schwarz, Nassir Navab, Federico Tombari"],"categories":null,"content":"","date":1553122800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1553122800,"objectID":"c04c2e71a988c79a7f8bf6647699e282","permalink":"https://menaveenshankar.github.io/publication/icra19/","publishdate":"2019-03-21T00:00:00+01:00","relpermalink":"/publication/icra19/","section":"publication","summary":"Lane change prediction of surrounding vehicles is a key building block of path planning. The focus has been on increasing the accuracy of prediction by posing it purely as a function estimation problem at the cost of model understandability. However, the efficacy of any lane change prediction model can be improved when both corner and failure cases are humanly understandable. We propose an attention-based recurrent model to tackle both understandability and prediction quality. We also propose metrics which reflect the discomfort felt by the driver. We show encouraging results on a publicly available dataset and proprietary fleet data.","tags":[],"title":"Attention-based Lane Change Prediction","type":"publication"},{"authors":null,"categories":null,"content":" In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 \u0026hellip;\nTip 2 \u0026hellip;\n","date":1536444000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1536444000,"objectID":"44d4380d50fe128183cbfb742c93533c","permalink":"https://menaveenshankar.github.io/misc/example/","publishdate":"2018-09-09T00:00:00+02:00","relpermalink":"/misc/example/","section":"misc","summary":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 \u0026hellip;\nTip 2 \u0026hellip;","tags":null,"title":"Example Page","type":"docs"},{"authors":["_Naveen Shankar Nagaraja_, [Frank R. Schmidt](https://www.frank-r-schmidt.de), [Thomas Brox](https://lmb.informatik.uni-freiburg.de/people/brox/)"],"categories":null,"content":"","date":1449788400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1449788400,"objectID":"6e3617a491b8b3f49d4a8fccb0e554b5","permalink":"https://menaveenshankar.github.io/publication/iccv15/","publishdate":"2015-12-11T00:00:00+01:00","relpermalink":"/publication/iccv15/","section":"publication","summary":"As the use of videos is becoming more popular in computer vision, the need for annotated video datasets increases. Such datasets are required either as training data or simply as ground truth for benchmark datasets. A particular challenge in video segmentation is due to disocclusions, which hamper frame-to-frame propagation, in conjunction with non-moving objects. We show that a combination of motion from point trajectories, as known from motion segmentation, along with minimal supervision can largely help solve this problem. Moreover, we integrate a new constraint that enforces consistency of the color distribution in successive frames. We quantify user interaction effort with respect to segmentation quality on challenging ego motion videos. We compare our approach to a diverse set of algorithms in terms of user effort and in terms of performance on common video segmentation benchmarks.","tags":[],"title":"Video Segmentation with Just a Few Strokes","type":"publication"},{"authors":["F. Galasso, _Naveen Shankar Nagaraja_, T. Cardenas, [Thomas Brox](https://lmb.informatik.uni-freiburg.de/people/brox/), B. Schiele"],"categories":null,"content":"","date":1385852400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1385852400,"objectID":"bfdf38b78af7871118774ef6754ccb0d","permalink":"https://menaveenshankar.github.io/publication/iccv13/","publishdate":"2013-12-01T00:00:00+01:00","relpermalink":"/publication/iccv13/","section":"publication","summary":"Video segmentation research is currently limited by the lack of a benchmark dataset that covers the large variety of subproblems appearing in video segmentation and that is large enough to avoid overfitting. Consequently, there is little analysis of video segmentation which generalizes across subtasks, and it is not yet clear which and how video segmentation should leverage the information from the still-frames, as previously studied in image segmentation, alongside video specific information, such as temporal volume, motion and occlusion. In this work we provide such an analysis based on annotations of a large video dataset, where each video is manually segmented by multiple per sons. Moreover, we introduce a new volume-based metric that includes the important aspect of temporal consistency, that can deal with segmentation hierarchies, and that reflects the tradeoff between over-segmentation and segmentation accuracy.","tags":[],"title":"A Unified Video Segmentation Benchmark: Annotation, Metrics, and Analysis","type":"publication"},{"authors":["_Naveen Shankar Nagaraja_, [Peter Ochs](http://www.mop.uni-saarland.de/index.shtml), Kun Liu, [Thomas Brox](https://lmb.informatik.uni-freiburg.de/people/brox/)"],"categories":null,"content":"","date":1346104800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1346104800,"objectID":"6911c0e39cd8ce1f6651d39384860886","permalink":"https://menaveenshankar.github.io/publication/dagm12/","publishdate":"2012-08-28T00:00:00+02:00","relpermalink":"/publication/dagm12/","section":"publication","summary":"We address the problem of annotating a video sequence with partial supervision. Given the pixel-wise annotations in the first frame, we aim to propagate these labels ideally throughout the whole video. While some labels can be propagated using optical flow, disocclusion and unreliable flow in some areas require additional cues. To this end, we propose to train localized classifiers on the annotated frame. In contrast to a global classifier, localized classifiers allow to distinguish colors that appear in both the foreground and the background but at very different locations. We design a multi-scale hierarchy of localized random forests, which collectively takes a decision. Cues from optical flow and the classifier are combined in a variational framework. The approach can deal with multiple objects in a video. We present qualitative and quantitative results on the Berkeley Motion Segmentation Dataset.","tags":[],"title":"Hierarchy of Localized Random Forests for Video Annotation","type":"publication"},{"authors":["_Naveen Shankar Nagaraja_, K. R. Ramakrishnan"],"categories":null,"content":"","date":1279404000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1279404000,"objectID":"82aabc6ee47756ce73fe57fb5e3a71ec","permalink":"https://menaveenshankar.github.io/publication/spcom10/","publishdate":"2010-07-18T00:00:00+02:00","relpermalink":"/publication/spcom10/","section":"publication","summary":"Computer Vision has seen a resurgence in the parts-based representation for objects over the past few years. The parts are usually annotated beforehand for training. We present an annotation free parts-based representation for the pedestrian using Non-Negative Matrix Factorization (NMF). We show that NMF is able to capture the wide range of pose and clothing of the pedestrians. We use a modified form of NMF i.e. NMF with sparsity constraints on the factored matrices. We also make use of Riemannian distance metric for similarity measurements in NMF space as the basis vectors generated by NMF aren't orthogonal. We show that for 1% drop in accuracy as compared to the Histogram of Oriented Gradients (HOG) representation we can achieve robustness to partial occlusion.","tags":[],"title":"Parts based representation for pedestrian using NMF with robustness to partial occlusion","type":"publication"},{"authors":null,"categories":null,"content":" Welcome to Slides Academic\nFeatures  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides  Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E  Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)  Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = \\;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \nA fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears  Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view   Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links   night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links  Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/img/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}  Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }  Questions? Ask\nDocumentation\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"c2915ec5da95791851caafdcba9664af","permalink":"https://menaveenshankar.github.io/slides/example-slides/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/slides/example-slides/","section":"slides","summary":"Welcome to Slides Academic\nFeatures  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides  Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E  Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)  Math In-line math: $x + y = z$","tags":null,"title":"Slides","type":"slides"}]